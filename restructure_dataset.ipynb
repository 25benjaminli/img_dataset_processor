{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define globals\n",
    "path = os.getcwd()\n",
    "data = \"\"\n",
    "names = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This assumes that you have a dataset with the following structure\n",
    "dataset\n",
    "\n",
    "|--> train\n",
    "<br>\n",
    "    |--> images\n",
    "    <br>\n",
    "    |--> labels\n",
    "\n",
    "|--> valid\n",
    "<br>\n",
    "    |--> images\n",
    "    <br>\n",
    "    |--> labels\n",
    "\n",
    "|--> test\n",
    "<br>\n",
    "    |--> images\n",
    "    <br>\n",
    "    |--> labels\n",
    "\n",
    "data.yaml\n",
    "\n",
    "#### 1. rename all files in the dataset to consistent names\n",
    "\n",
    "#### 2. split samples based on how many objects there are per image (try to approximate as well as possible)\n",
    "\n",
    "#### 3. create data.yaml file\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_classes(new_base='final_ds', old_base='ds'):\n",
    "    # doing stuff\n",
    "    shutil.rmtree(old_base)\n",
    "    shutil.copytree(old_base, f'{old_base}_copy')\n",
    "\n",
    "    # read data.yaml from {old_base}\n",
    "    with open(f'{old_base}/data.yaml', 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # remove everything after \"roboflow\"\n",
    "    data = data.split('roboflow')[0] # this will be the same...\n",
    "\n",
    "    # get all names from data.yaml\n",
    "    names = eval(data.split('names: ')[1])\n",
    "    print(names)\n",
    "\n",
    "    # rewrite train, val, test to go to final_ds/{split}/images instead of ../{split}/images\n",
    "    data = data.replace('../train/images', f'{new_base}/train/images').replace('../valid/images', f'{new_base}/valid/images').replace('../test/images', f'{new_base}/test/images')\n",
    "\n",
    "    print('data: ', data)\n",
    "\n",
    "    return data\n",
    "\n",
    "def remove_existing_backgrounds(old_base='ds', symbol='background'):\n",
    "    # remove all background images from {old_base}\n",
    "    for split in os.listdir(old_base):\n",
    "        if split == 'train' or split == 'valid' or split == 'test':\n",
    "            for filename in os.listdir(f'{old_base}/{split}/images'):\n",
    "                first_part, ext = os.path.splitext(filename)\n",
    "                if symbol in filename:\n",
    "                    os.remove(f'{old_base}/{split}/images/{filename}')\n",
    "                    os.remove(f'{old_base}/{split}/labels/{first_part}.txt')\n",
    "\n",
    "    print(len(os.listdir(f'{old_base}/train/images')) + len(os.listdir(f'{old_base}/valid/images')) + len(os.listdir(f'{old_base}/test/images')))\n",
    "\n",
    "\n",
    "def clean_roboflow_dataset(old_base='ds'):\n",
    "    # get index of \"_jpg\" \n",
    "    names = ['aphanizomenon', 'detritus', 'dolichospermum', 'microcystis', 'oscillatoria', 'water bubble', 'woronichinia']\n",
    "    for split in os.listdir(old_base):\n",
    "        if split == 'test' or split == 'train' or split == 'valid':\n",
    "            print(split)\n",
    "            for image in os.listdir(f'{old_base}/{split}/images'):\n",
    "                # get index of \"_jpg\"\n",
    "                image_name, ext = os.path.splitext(image)\n",
    "                new_image = image[:image.rfind('_')] + ext\n",
    "                # replace current image with new image\n",
    "                # get image path\n",
    "                new_image_name  = image[:image.rfind('_')]\n",
    "\n",
    "                os.rename(f'{old_base}/{split}/images/{image}', f'{old_base}/{split}/images/{new_image}')\n",
    "                os.rename(f'{old_base}/{split}/labels/{image_name}.txt', f'{old_base}/{split}/labels/{new_image_name}.txt')\n",
    "\n",
    "                found = False\n",
    "                for comp_name in names:\n",
    "                    if comp_name.lower() in new_image.lower():\n",
    "                        found = True\n",
    "                        break\n",
    "                \n",
    "                if not found:\n",
    "                    # this is for lab images that do not have the name associated to it\n",
    "                    \n",
    "                    # retrieve label from corresponding txt file\n",
    "                    if os.path.exists(f'{}/{split}/labels/{new_image_name}.txt'):   \n",
    "                        with open(f'{old_base}/{split}/labels/{new_image_name}.txt', 'r') as f:\n",
    "                            label = f.read()\n",
    "                            if len(label) > 0:\n",
    "                                label = int(label.split(' ')[0])\n",
    "                                # copy image to corresponding folder\n",
    "                                os.rename(f'{old_base}/{split}/images/{new_image}', f'{old_base}/{split}/images/{names[label]}-{new_image}')\n",
    "                                # copy label to corresponding folder\n",
    "                                os.rename(f'{old_base}/{split}/labels/{new_image_name}.txt', f'{old_base}/{split}/labels/{names[label]}-{new_image_name}.txt')\n",
    "\n",
    "def generate_CLAHE(image_path, output_path, grayscale = False):\n",
    "    if not grayscale:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        lab = cv2.cvtColor(cv2.cvtColor(image, cv2.COLOR_RGB2BGR), cv2.COLOR_BGR2LAB)\n",
    "        lab_planes = list(cv2.split(lab))\n",
    "        \n",
    "        clahe = cv2.createCLAHE(clipLimit=4, tileGridSize=(32,32))\n",
    "        lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "        lab = cv2.merge(tuple(lab_planes))\n",
    "        bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "        image = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "    else:\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.resize(image, (512, 512))\n",
    "        clahe = cv2.createCLAHE(clipLimit=4, tileGridSize=(32,32))\n",
    "        image = clahe.apply(image)\n",
    "    \n",
    "    cv2.imwrite(output_path, image)\n",
    "\n",
    "def preprocess(useCLAHE = False, grayscale = False, base = 'final_ds'):\n",
    "    # images are already resized to 512x512\n",
    "    # apply CLAHE to images\n",
    "    for split in os.listdir(base):\n",
    "        if split == 'train' or split == 'test' or split == 'valid':\n",
    "            for img_path in os.listdir(f'{base}/{split}/images'):\n",
    "                \n",
    "                image = cv2.imread(f'{base}/{split}/images/{img_path}')\n",
    "                image = cv2.resize(image, (512, 512))\n",
    "\n",
    "                cv2.imwrite(f'{base}/{split}/images/{img_path}', image)\n",
    "                \n",
    "                if useCLAHE:\n",
    "                    generate_CLAHE(f'{base}/{split}/images/{img_path}', f'{base}/{split}/images/{img_path}', grayscale)\n",
    "\n",
    "                else:\n",
    "                    cv2.imwrite(f'{base}/{split}/images/{img_path}', image)\n",
    "\n",
    "def check_for_incorrect_labels(old_base='ds'):\n",
    "    for split in os.listdir(f'{old_base}'):\n",
    "        if split == 'train' or split == 'valid' or split == 'test':\n",
    "            for image in os.listdir(f'{old_base}/{split}/images'):\n",
    "                matches = False\n",
    "                for name in names:\n",
    "                    if name.lower() in image.lower():\n",
    "                        if not os.path.exists(f'{old_base}/{split}/labels/{image[:-4]}.txt'):\n",
    "                            continue\n",
    "                        with open(f'{old_base}/{split}/labels/{image[:-4]}.txt', 'r') as f:\n",
    "                            data = f.read()\n",
    "                            if len(data) == 0:\n",
    "                                continue\n",
    "                            data = int(data.split(' ')[0])\n",
    "\n",
    "                            if names[data] == name:\n",
    "                                matches = True\n",
    "                                break\n",
    "                if not matches:\n",
    "                    print(f'{old_base}/{split}/images/{image}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid\n",
      "test\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "# delete_all_folders()\n",
    "clean_names('dataset')\n",
    "set_name_and_paths('dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_dataset_processor-dGMadnFC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
