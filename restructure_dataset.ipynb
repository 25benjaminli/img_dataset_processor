{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "path = os.getcwd()\n",
    "data = \"\"\n",
    "names = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This assumes that you have a dataset with the following structure\n",
    "dataset\n",
    "\n",
    "|--> train\n",
    "<br>\n",
    "    |--> images\n",
    "    <br>\n",
    "    |--> labels\n",
    "\n",
    "|--> valid\n",
    "<br>\n",
    "    |--> images\n",
    "    <br>\n",
    "    |--> labels\n",
    "\n",
    "|--> test\n",
    "<br>\n",
    "    |--> images\n",
    "    <br>\n",
    "    |--> labels\n",
    "\n",
    "data.yaml\n",
    "\n",
    "#### 1. rename all files in the dataset to consistent names\n",
    "\n",
    "#### 2. split samples based on how many objects there are per image (try to approximate as well as possible)\n",
    "\n",
    "#### 3. create data.yaml file\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_folders():\n",
    "    shutil.rmtree(path + \"/combined_ds\")\n",
    "    shutil.rmtree(path + \"/org_ds\")\n",
    "    shutil.rmtree(path + \"/final_ds\")\n",
    "\n",
    "# roboflow does a weird thing where it inserts .rf in the middle so you need to remove it\n",
    "def clean_names(dataset_name):\n",
    "    for split in os.listdir(dataset_name):\n",
    "        if split == 'test' or split == 'train' or split == 'valid':\n",
    "            print(split)\n",
    "            for img in os.listdir(f'{dataset_name}/{split}/images'):\n",
    "                # rename image at this path to remove \"_jpg\"\n",
    "                name, extension = os.path.splitext(img)\n",
    "                # assume that the file is already in jpg form\n",
    "                name = name[:name.rfind('_')]\n",
    "                os.rename(f'{dataset_name}/{split}/images/{img}', f'{dataset_name}/{split}/images/{name}{extension}')\n",
    "\n",
    "    \n",
    "def set_name_and_paths(dataset_name):\n",
    "    # read data.yaml from b_ds\n",
    "    global data\n",
    "    global names\n",
    "    with open(f'{dataset_name}/data.yaml', 'r') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    # remove everything after \"roboflow\"\n",
    "    \n",
    "    data = data.split('roboflow')[0] # this will be the same...\n",
    "\n",
    "    # get all names from data.yaml\n",
    "    names = data.split('names: ')[1]\n",
    "\n",
    "    # convert string names to list\n",
    "    names = eval(names)\n",
    "    print(names)\n",
    "\n",
    "    # rewrite train, val, test to go to final_ds/{split}/images instead of ../{split}/images\n",
    "    data = data.replace('../train/images', 'final_ds/train/images')\n",
    "    data = data.replace('../valid/images', 'final_ds/valid/images')\n",
    "    data = data.replace('../test/images', 'final_ds/test/images')\n",
    "\n",
    "    print(data)\n",
    "\n",
    "\n",
    "def organize_to_names():\n",
    "    # assert background_proportion >= 0 and background_proportion <= 1, \"background_proportion must be between 0 and 1\"\n",
    "\n",
    "    names_with_freqs = [0 for i in range(len(names))]\n",
    "    x=0\n",
    "\n",
    "    for name in names:\n",
    "        if os.path.exists(path + f\"/org_ds/{name}\"):\n",
    "            shutil.rmtree(path + f\"/org_ds/{name}\")\n",
    "        os.makedirs(path + f\"/org_ds/{name}\")\n",
    "    \n",
    "    if os.path.exists(path + f\"/org_ds/labels\"):\n",
    "            shutil.rmtree(path + f\"/org_ds/labels\")\n",
    "    os.makedirs(path + f\"/org_ds/labels\")\n",
    "\n",
    "    if os.path.exists(path + f\"/org_ds/backgrounds\"):\n",
    "        shutil.rmtree(path + f\"/org_ds/backgrounds\")\n",
    "    os.makedirs(path + f\"/org_ds/backgrounds\")\n",
    "    \n",
    "    for label in os.listdir(path + \"/combined_ds/labels\"):\n",
    "        # organize everything into folders based on\n",
    "        \n",
    "        with open(path + f\"/combined_ds/labels/{label}\") as file:\n",
    "            # read first line\n",
    "            asdf = file.readline().split(\" \")[0]\n",
    "            # print(asdf)\n",
    "            try:\n",
    "                numval = int(asdf)\n",
    "                real_name = names[numval]\n",
    "                \n",
    "                # move image and label to folder\n",
    "                names_with_freqs[numval] += 1\n",
    "\n",
    "                name, extension = os.path.splitext(real_name)\n",
    "\n",
    "                # fix fix fix \n",
    "                shutil.copy(path + f\"/combined_ds/images/{name}{extension}\", path + f\"/org_ds/{real_name}/{real_name}.jpg\")\n",
    "                shutil.copy(path + f\"/combined_ds/labels/{label}\", path + f\"/org_ds/labels/{real_name}.txt\")\n",
    "                    \n",
    "                x+=1\n",
    "            except:\n",
    "                # label does not exist\n",
    "                shutil.copy(path + f\"/combined_ds/images/{label[:-4]}.jpg\", path + f\"/org_ds/backgrounds/{label[:-4]}_background.jpg\")\n",
    "                continue\n",
    "\n",
    "\n",
    "def get_splits(ratios, background_proportion=0.1):\n",
    "    ftrain, fval, ftest = np.array([]), np.array([]), np.array([])\n",
    "    # stratify splitting of data\n",
    "    print(\"getting splits\")\n",
    "    for name in names:\n",
    "        allFileNames = os.listdir(path + f\"/org_ds/{name}\")\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(allFileNames)\n",
    "\n",
    "        train, val, test = np.split(np.array(allFileNames),[int(len(allFileNames)*0.8), int(len(allFileNames)*0.9)])\n",
    "\n",
    "        ftrain = np.concatenate((ftrain, train))\n",
    "        fval = np.concatenate((fval, val))\n",
    "        ftest = np.concatenate((ftest, test))\n",
    "\n",
    "        print(name, len(train), len(val), len(test))\n",
    "    \n",
    "    \n",
    "\n",
    "    if background_proportion > 0:\n",
    "        # calculate number of backgrounds to add\n",
    "        num_backgrounds = (len(ftrain)*background_proportion)/(1-background_proportion)\n",
    "        allFileNames = os.listdir(path + f\"/org_ds/backgrounds\")\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(allFileNames)\n",
    "\n",
    "        train, val, test = np.split(np.array(allFileNames),[int(len(allFileNames)*0.8), int(len(allFileNames)*0.9)])\n",
    "\n",
    "        train = train[:num_backgrounds]\n",
    "        val = val[:num_backgrounds]\n",
    "        test = test[:num_backgrounds]\n",
    "\n",
    "        ftrain = np.concatenate((ftrain, train))\n",
    "        fval = np.concatenate((fval, val))\n",
    "        ftest = np.concatenate((ftest, test))\n",
    "\n",
    "    print(\"final lengths after stratified split: \", len(ftrain), len(fval), len(ftest))\n",
    "    \n",
    "    global globftrain\n",
    "    global globfval\n",
    "    global globftest\n",
    "    globftrain = ftrain\n",
    "    globfval = fval\n",
    "    globftest = ftest\n",
    "    \n",
    "    return ftrain, fval, ftest\n",
    "\n",
    "def generate_dataset(dataset_name, exclude_classes = ['anabaena'], ratios = [0.8, 0.1, 0.1], background_proportion=0.1):\n",
    "    clean_names(dataset_name)\n",
    "    set_name_and_paths(dataset_name)\n",
    "    organize_to_names(background_proportion)\n",
    "    ftrain, fval, ftest = get_splits(ratios, background_proportion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid\n",
      "test\n",
      "train\n"
     ]
    }
   ],
   "source": [
    "# delete_all_folders()\n",
    "clean_names('dataset')\n",
    "set_name_and_paths('dataset')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This program works by \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_dataset_processor-dGMadnFC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
